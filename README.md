
# wildchat-hard-ru

1000 заданий на русском языке для SBS-оценки LLM.

<img src="i/Снимок экрана 2025-04-28 в 16.10.04.png" />

Решает проблемы, существующих российских датасетов:

- В <a href="https://huggingface.co/datasets/t-tech/ru-alpaca-eval">ru-alpaca-eval</a> слишком простые задания для современных LLM: "Какой океан самый большой в мире?", "Что такое Атлантида?". Авторы явно <a href="https://github.com/tatsu-lab/alpaca_eval/tree/f19c323d8309d0d6f306bd26597db44fc6c62d57?tab=readme-ov-file#limitations">пишут об этом в LIMITATIONS</a>: "might not be representative of real-usage and advanced applications".
- В <a href="https://huggingface.co/datasets/t-tech/ru-mt-bench">ru-mt-bench</a> всего 80 заданий.
- В <a href="https://huggingface.co/datasets/t-tech/ru-arena-hard">ru-arena-hard</a> половина заданий про программирование, аудитория http://lmarena.ai в основном технари.
- Все датасеты Т-банк автоматически перевел с английского на русский и проверил вручную. В текстах нет опечаток, правильно проставлены запятые, задания идеально сформулированы. Реальные юзеры пишут с ошибками, криво формулируют запросы.

<table>
<tr>
  <th></th>
  <th>ru-alpaca-eval</th>
  <th>ru-mt-bench</th>
  <th>ru-arena-hard</th>
  <th>wildchat-hard-ru</th>
</tr>

<tr>
  <th>Размер датасета</th>
  <td>800</td>
  <td>(!) 80</td>
  <td>500</td>
  <td>1000</td>
</tr>

<tr>
  <th>Средняя сложность (<a href="https://github.com/kuk/wildchat-hard-ru/blob/d980ec95523b0eed0e43c7d09eed1b7895f85595/main.py#L131">промпт от Lmsys</a>)</th>
  <td>(!) 3.1</td>
  <td>4.1</td>
  <td>4.8</td>
  <td>5.4</td>
</tr>

<tr>
  <th>Распределение по категориям</th>
  <td>
42%&nbsp;Info&nbsp;seeking<br/>
10%&nbsp;Writing<br/>
9%&nbsp;Brainstorming<br/>
8%&nbsp;Advice<br/>
7%&nbsp;Reasoning<br/>
...
  </td>
  <td>
19%&nbsp;Info&nbsp;seeking<br/>
16%&nbsp;Reasoning<br/>
15%&nbsp;Math<br/>
12%&nbsp;Coding<br/>
10%&nbsp;Role&nbsp;playing<br/>
...
  </td>
  <td>
(!) 51%&nbsp;Coding<br/>
14%&nbsp;Info&nbsp;seeking<br/>
7%&nbsp;Reasoning<br/>
6%&nbsp;Planning<br/>
5%&nbsp;Math<br/>

...
  </td>
  <td>
15%&nbsp;Coding<br/>
14%&nbsp;Writing<br/>
14%&nbsp;Info&nbsp;seeking<br/>
12%&nbsp;Editing<br/>
12%&nbsp;Brainstorming<br/>
...
  </td>

</tr>

<tr>
  <th>Автоматический перевод с английского?</th>
  <td>Перевод</td>
  <td>Перевод</td>
  <td>Перевод</td>
  <td>Изначально на русском</td>
</tr>
</table>

## Рецепт

### Взять русскоязычный срез Wildchat-1m и Lmsys-chat-1m

- Lmsys-chat-1m - https://arxiv.org/abs/2309.11998, https://huggingface.co/datasets/lmsys/lmsys-chat-1m/tree/main/data.
- Wildchat-1m - https://arxiv.org/abs/2405.01470, https://huggingface.co/datasets/allenai/WildChat-1M/tree/main/data.
- В обоих датасетах русский язык в топ-3, никакие преграды неспособны остановить русского человека которому надо -решить домашку по алгебре- прикоснуться к современным технологиям.
- В Lmsys-chat-1m 27к заданий на русском, в Wildchat-1m - 83к, итого 100к заданий. Подозреваю. что через беспланый API Wildchat ходили отдельные российские телеграм-боты прокси к Chatgpt, это объясняет почему доля в ~3 раза больше.
- Авторы приложили усилия, чтобы почистить перс данные, прогнали задания через Openai Moderation API. Остается намайнить из них тыщу разнообразных +- сложных.

### Оставить 50 < len < 5000

- Из 100к остается 68к, уже легче.
- В 50 символов сложно уместить содержательное задание, 3 случайных: "привет" "Жопа" "Привет, ты кто?".
- Ворочать заданиями на 5000+ символов просто дорого / неудобно, их 2%.

### Дедуплицировать по cosine distance

- Использую Openai text-embedding-3-small, дешево, результат на глаз не отличается от large.
- Использую Dbscan, внутри кластера могут быть пары с cosine distance > 0.8, забиваю на этот нюанс. Число 0.8 беру +- с потолка.
- Из каждого кластера беру самое длинное задание, надеюсь что оно будет посложнее и не будет обрываться на середине.
- 68к заданий превращаются в 51к.

<img src="i/Снимок экрана 2025-04-29 в 10.53.21.png" />

### Классифицировать задания промптом из Wildbench

- Промпт из Wildbench - https://arxiv.org/abs/2406.04770v1, https://github.com/kuk/wildchat-hard-ru/blob/d980ec95523b0eed0e43c7d09eed1b7895f85595/main.py#L179
- Промпт классифицирует все многообразие запросов к LLM на 10 категорий, это конечно упрощений. Некоторые категории хорошо очерчены - "Coding & Debugging", "Math"; некоторые расплывчатые - "Reasoning", "Brainstorming", "Information seeking". Моя задача не идеально классифицировать поток, а сделать репрезентативную выборку из 1к заданий, не скатиться в ситуацию когда половина пула про программирование.
- Использую Gemini Flash 2. Разметил 500 заданий тремя топовыми моделями, Flash 2 угадала 81% от majority vote.

<img src="i/Снимок экрана 2025-04-29 в 12.29.20.png" />
<img src="i/Снимок экрана 2025-04-29 в 12.30.06.png" />
<img src="i/Снимок экрана 2025-04-29 в 12.30.48.png" />
<img src="i/Снимок экрана 2025-04-29 в 12.31.23.png" />
<img src="i/Снимок экрана 2025-04-29 в 12.31.42.png" />

Раскрасил Umap укладку, точки из одной категории кучкуются +- рядом:

<img src="i/Снимок экрана 2025-04-29 в 12.53.27.png" />

### Определить сложность промптом от Lmsys

- Промпт от Lmsys - https://arxiv.org/abs/2406.11939, https://github.com/kuk/wildchat-hard-ru/blob/d980ec95523b0eed0e43c7d09eed1b7895f85595/main.py#L131
- Промпт ставит заданию скор сложности от 0 до 7. Критерии супер расплывчатые. Взял 500 заданий, прогнал три топовые модели, на глаз корелляция есть но слабенькая. Ничего лучше не придумал, использую этот промпт.
- Использую Gemini Flash 2. Чтобы замерить точность, свел задачу к бинарной классификации - "сложно >= 5?", разметил 500 заданий тремя топовыми моделями, Flash 2 угадала 80% от majority vote. Моя задача не разложить задания по категориям сложности, а убрать примитивные задания.

Распредение по категориям внутри скоров сложности:

- Для скоров 0 и 7 мало примеров, на них не обращую внимания.
- С ростом сложности растет доля "Coding & Debugging", "Math"; падает доля "Information seeking", "Creative writing".

<img src="i/Снимок экрана 2025-04-29 в 12.52.18.png" />

### Кластеризовать Kmeans, семплить равномерно по категориям, максимизировать сложность

- Понизил размерность через Umap до 6 (по-моему это число из BertTopic). Разбил 51к заданий на 3к кластеров через Kmeans. Для каждого кластера определил сложность и категорию кластера: сложноть - медианная сложность заданий внутри кластера, категория - категория которая встречается чаще всего внутри кластера.
- Хожу по циклу из категорий, для каждой категории бегу кластер максимальной сложности, из кластера беру одно самое сложное задание, кластер выкидываю. Так повторяю пока не наберется 1к заданий.

Нюансы:
- Есть мелкие кластера из 2-10 заданий, для них сложность / категория определена ненадежно, внутри кластеров с одинаковой сложностью / категорией я выбирают самый крупный
- Я набираю не 1000 заданий, а 1100 с небольшим запасом, чтобы если встречу плохие задания отфильтровать их вручную. Например, я отфильтровал задания с подстроками "http://" "https://" чтобы не требовать от LLM скачивать статьи из интернета.

## Разработка

```
uv sync
uv run ipython kernel install --user --name wildchat-hard-ru
```
